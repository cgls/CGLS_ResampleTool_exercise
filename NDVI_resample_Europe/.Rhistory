perc_subsample <- 1   # percentage of points for plotting
num_subsample <- round((nrow(rsmpl_df) * perc_subsample / 100), 0)
rsmpl_df_subsample <- rsmpl_df[sample(nrow(rsmpl_df), num_subsample), ]
jpeg(paste0(path2save, "/resample_correlation_RAggr.jpg"))
xyplot(rsmpl_df_subsample$getValues.r300m_resampled1km_Aggr. ~ rsmpl_df_subsample$getValues.ndvi1km_rstr.,
type = c("p", "r"),
col.line = "red",
main = paste0("Pearson's r = ", as.character(round(rsmpl_df_pearson, 4))),
sub = paste0("Plotting a random subsample of ", num_subsample, " (", perc_subsample, "%) points")
)
dev.off()
cor(rsmpl_df, method = "pearson")
jpeg(paste0(path2save, "/resample_correlation_RAggr.jpg"))
xyplot(rsmpl_df_subsample$getValues.r300m_resampled1km_Aggr. ~ rsmpl_df_subsample$getValues.ndvi1km_rstr.,
type = c("p", "r"),
col.line = "red",
xlab = "1km original NDVI product",
ylab = "1km resampled NDVI image",
main = paste0("Pearson's r = ", as.character(round(rsmpl_df_pearson, 4))),
sub = paste0("Plotting a random subsample of ", num_subsample, " (", perc_subsample, "%) points")
)
dev.off()
rsmpl_df$diff <- abs(rsmpl_df$getValues.ndvi1km_rstr. - rsmpl_df$getValues.r300m_resampled1km_Aggr.)
rsmpl_df$diff1 <- abs(round(rsmpl_df$getValues.ndvi1km_rstr., 1) - round(rsmpl_df$getValues.r300m_resampled1km_Aggr., 1))
rsmpl_df$diff3 <- abs(round(rsmpl_df$getValues.ndvi1km_rstr., 3) - round(rsmpl_df$getValues.r300m_resampled1km_Aggr., 3))
summary(rsmpl_df$diff)
summary(rsmpl_df$diff1)
summary(rsmpl_df$diff3)
jpeg(paste0(path2save, "/resample_correlation_RAggr_1dec.jpg"))
xyplot(round(rsmpl_df_subsample$getValues.r300m_resampled1km_Aggr., 1) ~ round(rsmpl_df$getValues.ndvi1km_rstr., 1),
type = c("p", "r"),
col.line = "red",
xlab = "1km original NDVI product",
ylab = "1km resampled NDVI image",
main = paste0("Pearson's r = ", as.character(round(rsmpl_df_pearson, 4))),
sub = paste0("Plotting a random subsample of ", num_subsample, " (", perc_subsample, "%) points")
)
dev.off()
jpeg(paste0(path2save, "/resample_correlation_RAggr_3dec.jpg"))
xyplot(round(rsmpl_df_subsample$getValues.r300m_resampled1km_Aggr., 3) ~ round(rsmpl_df$getValues.ndvi1km_rstr., 3),
type = c("p", "r"),
col.line = "red",
xlab = "1km original NDVI product",
ylab = "1km resampled NDVI image",
main = paste0("Pearson's r = ", as.character(round(rsmpl_df_pearson, 4))),
sub = paste0("Plotting a random subsample of ", num_subsample, " (", perc_subsample, "%) points")
)
dev.off()
jpeg(paste0(path2save, "/resample_correlation_RAggr_3dec.jpg"))
xyplot(round(rsmpl_df_subsample$getValues.r300m_resampled1km_Aggr., 3) ~ round(rsmpl_df_subsample$getValues.ndvi1km_rstr., 3),
type = c("p", "r"),
col.line = "red",
xlab = "1km original NDVI product",
ylab = "1km resampled NDVI image",
main = paste0("Pearson's r = ", as.character(round(rsmpl_df_pearson, 4))),
sub = paste0("Plotting a random subsample of ", num_subsample, " (", perc_subsample, "%) points")
)
dev.off()
jpeg(paste0(path2save, "/resample_correlation_RAggr_1dec.jpg"))
xyplot(round(rsmpl_df_subsample$getValues.r300m_resampled1km_Aggr., 1) ~ round(rsmpl_df_subsample$getValues.ndvi1km_rstr., 1),
type = c("p", "r"),
col.line = "red",
xlab = "1km original NDVI product",
ylab = "1km resampled NDVI image",
main = paste0("Pearson's r = ", as.character(round(rsmpl_df_pearson, 4))),
sub = paste0("Plotting a random subsample of ", num_subsample, " (", perc_subsample, "%) points")
)
dev.off()
summary(rsmpl_df$diff)
summary(rsmpl_df$diff1)
summary(rsmpl_df$diff3)
summary(rsmpl_df$diff1)
seq(0:1, 0.1)
seq(0, 1, 0.1)
quantile(rsmpl_df$diff1, seq(0, 1, 0.1))
sqrt(mean((rsmpl_df$diff)^2))
rsmpl_df_cov_pearson <- cov(rsmpl_df, method = "pearson")
rsmpl_df_cov_pearson
rsmpl_df_cov_pearson <- cov(rsmpl_df[, 1:2], method = "pearson")
rsmpl_df_cov_pearson
rsmpl_df_cov_pearson <- cov(rsmpl_df[, 1:2])
rsmpl_df_cov_pearson
# Root Mean Square Error (the lower, the better)
sqrt(mean((rsmpl_df$diff)^2))
summary(rsmpl_df$diff)
# Mean Absolute Error (MAE; the lower, the better)
mean((rsmpl_df$diff)))
# Mean Absolute Error (MAE; the lower, the better)
mean((rsmpl_df$diff))
# Root Mean Square Error (RMSE; the lower, the better)
sqrt(mean((rsmpl_df$diff)^2))
# Q-Q plot
jpeg(paste0(path2save, "/resample_QQplot_RAggr.jpg"))
qq(rsmpl_df_subsample$getValues.r300m_resampled1km_Aggr. ~ rsmpl_df_subsample$getValues.ndvi1km_rstr.
)
## Comparison 'original-1km' with '300m-resampled-1km-Aggr' ####
comp_results <- data.frame()
comp_results
names(comp_results) <- c("Pearson's r", "Root Mean Square Error", "Mean Absolute Error")
## Comparison 'original-1km' with '300m-resampled-1km-Aggr' ####
comp_results <- as.data.frame(matrix(ncol = 3))  #to store results
names(comp_results) <- c("Pearson's r", "Root Mean Square Error", "Mean Absolute Error")
comp_results
comp_results[1, 1] <- rsmpl_df_pearson
# Root Mean Square Error (RMSE; the lower, the better)
# In GIS, the RMSD is one measure used to assess the accuracy of spatial analysis and remote sensing.
rmse <- sqrt(mean((rsmpl_df$diff)^2))
comp_results[1, 2] <- rmse
# Mean Absolute Error (MAE; the lower, the better)
mae <- mean(rsmpl_df$diff)
comp_results[1, 3] <- mae
comp_results
## Comparison 'original-1km' with '300m-resampled-1km-Aggr' ####
comp_results <- as.data.frame(matrix(ncol = 3))  #to store results
## Comparison 'original-1km' with '300m-resampled-1km-Aggr' ####
comp_results <- as.data.frame(matrix(ncol = 4))  #to store results
names(comp_results) <- c("objects",
"Pearson's r", "Root Mean Square Error", "Mean Absolute Error")
comp_results[1,1] <- "original-1km_resampled-1km-RAggreg"
comp_results[1, 2] <- rsmpl_df_pearson
comp_results[1, 3] <- rmse
comp_results[1, 4] <- mae
comp_results
comp_results[1, 1] <- "orig-1km__resampl-1km-RAggreg"
comp_results
path2save
View(comp_results)
## Comparison 'original-1km' with '300m-resampled-1km-QGIS_Aggr' ####
comp_results[2, 1] <- "orig-1km__resampl-1km-QGIS-Aggreg"
comp_results
## Comparison '300m-resampled-1km-R_Aggr' with '300m-resampled-1km-QGIS_Aggr' ####
comp_results[3, 1] <- "orig-1km__resampl-1km-QGIS-Aggreg"
comp_results
## Comparison '300m-resampled-1km-R_Aggr' with '300m-resampled-1km-QGIS_Aggr' ####
comp_results[3, 1] <- "resampl-1km-R-Aggreg__resampl-1km-QGIS-Aggreg"
comp_results
# Saving stuff for the report
stuff2save <- c("comp_results", "my_extent")
save(list = stuff2save, file = paste0(path2save, "/ResampleResults4Report.RData"))
library(knitr)
library(pander)
library(captioner)
knitr::opts_chunk$set(echo = TRUE)
work_extent <- as.vector(my_extent)
work_extent
my_extent
paste(c("xmin = ", "xmax = ", "ymin = ", "ymax = "), work_extent)
raster(ndvi_1km_orig)
path2data
## Reading in data 1km global ####
nc <- nc_open(paste0(path2data, "/", nc_file1km))
nc_file1km
ndvi_1km_orig
ndvi_1km_orig
ndvi_1km_orig@data
ndvi_1km_orig@z
img_date <- unlist(ndvi_1km_orig@z)
img_date
img_date <- as.date(unlist(ndvi_1km_orig@z))
img_date <- as.Date(unlist(ndvi_1km_orig@z))
unlist(ndvi_1km_orig@z)
as.Date(unlist(ndvi_1km_orig@z), "%m/%d/%Y")
str(unlist(ndvi_1km_orig@z))
as.Date(as.character(unlist(ndvi_1km_orig@z)), "%m/%d/%Y")
as.character(unlist(ndvi_1km_orig@z))
ndvi_1km_orig@z)
ndvi_1km_orig@z
str(ndvi_1km_orig@z)
ndvi_1km_orig@z[[1]]
as.Date(ndvi_1km_orig@z[[1]], "%m/%d/%Y")
as.Date(ndvi_1km_orig@z[[1]])
format(as.Date(ndvi_1km_orig@z[[1]]), "%m/%d/%Y")
format(as.Date(ndvi_1km_orig@z[[1]]), "%B %d, %Y")
format(as.Date(ndvi_1km_orig@z[[1]]), "%B %d, %Y", locale = locale("en"))
format(as.Date(ndvi_1km_orig@z[[1]]), "%B %d, %Y", locale = locale("e"))
format(as.Date(ndvi_1km_orig@z[[1]]), "%B %d, %Y", locale = locale("eng"))
format(as.Date(ndvi_1km_orig@z[[1]]), "%B %d, %Y", locale = locale("English"))
format(as.Date(ndvi_1km_orig@z[[1]]), "%B %d, %Y", locale = locale("C"))
format(asDateTime(ndvi_1km_orig@z[[1]]), "%B %d, %Y", locale = locale("C"))
locale("C")
format(asDateTime(ndvi_1km_orig@z[[1]]), "%B %d, %Y", locale = "English")
format(as.Date(ndvi_1km_orig@z[[1]]), "%B %d, %Y", locale = "English")
format(as.Date(ndvi_1km_orig@z[[1]]), "%b %d, %Y", locale = "English")
Sys.setlocale("LC_TIME", "English")
Sys.setlocale("LC_TIME", "C")
format(as.Date(ndvi_1km_orig@z[[1]]), "%b %d, %Y")
format(as.Date(ndvi_1km_orig@z[[1]]), "%B %d, %Y")
# Saving stuff for the report
stuff2save <- c("comp_results", "my_extent", "img_date")
save(list = stuff2save, file = paste0(path2save, "/ResampleResults4Report.RData"))
ndvi_300m_orig_Eur
jpeg(paste0(path2save, "/ndvi_300m_orig_Eur.jpg"))
plot(ndvi_300m_orig_Eur)
dev.off()
my_extent
img_date <- ndvi_1km_orig@z
# Saving stuff for the report
stuff2save <- c("comp_results", "my_extent", "img_date")
img_date <- ndvi_1km_orig@z[[1]]
# Saving stuff for the report
stuff2save <- c("comp_results", "my_extent", "img_date")
save(list = stuff2save, file = paste0(path2save, "/ResampleResults4Report.RData"))
nc <- nc_open(paste0(path2data, "/", nc_file1km))
if(Sys.info()[4] == "D01RI1700371"){
path2data <- "E:/rotllxa/NDVI_resample/NDVI_data"
path2save <- "E:/rotllxa/NDVI_resample/NDVI_resample"
}else if(Sys.info()[4] == "h05-wad.ies.jrc.it"){
path2data <- ""
path2save <- ""
}else if(Sys.info()[4] == "MacBook-MacBook-Pro-de-Xavier.local"){
path2data <- "/Users/xavi_rp/Documents/D6_LPD/NDVI_data"
path2save <- "/Users/xavi_rp/Documents/D6_LPD/NDVI_resample"
}else{
stop("Define your machine before to run LPD")
}
nc_file1km <- "c_gls_NDVI_201908110000_GLOBE_PROBAV_V2.2.1.nc"
nc_file300m <- "c_gls_NDVI300_201908110000_GLOBE_PROBAV_V1.0.1.nc"
nc <- nc_open(paste0(path2data, "/", nc_file1km))
nc
nc <- nc_open(paste0(path2data, "/", nc_file1km))
lon <- ncvar_get(nc, "lon")
lat <- ncvar_get(nc, "lat")
time <- ncvar_get(nc, "time")
unique(time)
nc
View(comp_results)
range(rsmpl_df$getValues.r300m_resampled1km_Aggr.)
summary(rsmpl_df$diff)
summary(rsmpl_df$getValues.r300m_resampled1km_Aggr.)
paste0(comp_results[1, 3], "and", comp_results[1, 4], ", respectively")
library(knitr)
library(pander)
library(captioner)
library(raster)
knitr::opts_chunk$set(echo = TRUE)
comp_results[, 2:4] <- round(comp_results[, 2:4], 3)
paste0(comp_results[1, 3], "and", comp_results[1, 4], ", respectively")
citation()
citation("raster")
cor()
cor
citation("stats")
# ndvi_files is a list of the available files (netCFD or Raster* objects)
ndvi_files <- list(paste0(getwd(), "/ndvi300m_Cat_kk.tif"))
r <- raster(ndvi_files[[1]])
cutoff_method_df <- read.csv(paste0(getwd(), "/Table_cutoff_and_resampleMethod.csv"),
stringsAsFactors = FALSE,
header = TRUE)
View(cutoff_method_df)
kk <- c(1,2,3,4,5,6, NA, NA, NA)
length(!is.na(kk))
sum(!is.na(kk))
sum(!is.na(kk)) > 4
kk <- c(1,2,3,4,5,NA, NA, NA, NA)
sum(!is.na(kk)) > 4
kk <- c(1,2,3,4,NA,NA, NA, NA, NA)
sum(!is.na(kk)) > 4
?sqrt
if(Sys.info()[4] == "D01RI1700371"){
path2data <- "E:/rotllxa/NDVI_resample/NDVI_data"
path2save <- "E:/rotllxa/NDVI_resample/NDVI_resample_Europe"
}else if(Sys.info()[4] == "h05-wad.ies.jrc.it"){
path2data <- ""
path2save <- ""
}else if(Sys.info()[4] == "MacBook-MacBook-Pro-de-Xavier.local"){
path2data <- "/Users/xavi_rp/Documents/D6_LPD/NDVI_data"
path2save <- "/Users/xavi_rp/Documents/D6_LPD/NDVI_resample/NDVI_resample_Europe"
}else{
stop("Define your machine before to run LPD")
}
setwd(path2save)
nc_file300m <- paste0(path2data, "c_gls_NDVI300_PROD-DESC_202005010000_GLOBE_PROBAV_V1.0.1.nc")
qgis_resamp_europe_avrge <- paste0(path2data, "europa1000_aver.tif")
ndvi_1km_orig <- paste0(path2data, "/ndvi_v2_1km_c_gls_NDVI_202005010000_GLOBE_PROBAV_V2.2.1.nc")
ndvi_1km_orig
## Reading in data 1km global ####
ndvi_1km_orig <- raster(ndvi_1km_orig)
summary(as.data.frame(ndvi_1km_orig))
extent(qgis_resamp_europe_avrge)
qgis_resamp_europe_avrge <- raster(qgis_resamp_europe_avrge)
nc_file300m <- paste0(path2data, "c_gls_NDVI300_PROD-DESC_202005010000_GLOBE_PROBAV_V1.0.1.nc")
qgis_resamp_europe_avrge <- paste0(path2data, "europa1000_aver.tif")
ndvi_1km_orig <- paste0(path2data, "/ndvi_v2_1km_c_gls_NDVI_202005010000_GLOBE_PROBAV_V2.2.1.nc")
qgis_resamp_europe_avrge <- raster(qgis_resamp_europe_avrge)
qgis_resamp_europe_avrge <- projectRaster(from = qgis_resamp_europe_avrge,
res = (1/112),
crs = CRS('+init=EPSG:4326'),
method="bilinear",
alignOnly=FALSE, over=FALSE,
filename="")
qgis_resamp_europe_avrge <- projectRaster(from = qgis_resamp_europe_avrge,
res = (1/112),
crs = CRS('+init=EPSG:4326'),
method="bilinear",
alignOnly=FALSE, over=FALSE,
filename="")
rm(list = ls())
.rs.restartR()
## Settings
#rm(list = ls())
#.rs.restartR()
library(ncdf4)
library(fields)
library(raster)
library(rgdal)
library(lattice)
library(sf)
if(Sys.info()[4] == "D01RI1700371"){
path2data <- "E:/rotllxa/NDVI_resample/NDVI_data"
path2save <- "E:/rotllxa/NDVI_resample/NDVI_resample_Europe"
}else if(Sys.info()[4] == "h05-wad.ies.jrc.it"){
path2data <- ""
path2save <- ""
}else if(Sys.info()[4] == "MacBook-MacBook-Pro-de-Xavier.local"){
path2data <- "/Users/xavi_rp/Documents/D6_LPD/NDVI_data"
path2save <- "/Users/xavi_rp/Documents/D6_LPD/NDVI_resample/NDVI_resample_Europe"
}else{
stop("Define your machine before to run LPD")
}
setwd(path2save)
nc_file300m <- paste0(path2data, "c_gls_NDVI300_PROD-DESC_202005010000_GLOBE_PROBAV_V1.0.1.nc")
qgis_resamp_europe_avrge <- paste0(path2data, "europa1000_aver.tif")
ndvi_1km_orig <- paste0(path2data, "/ndvi_v2_1km_c_gls_NDVI_202005010000_GLOBE_PROBAV_V2.2.1.nc")
qgis_resamp_europe_avrge <- raster(qgis_resamp_europe_avrge)
qgis_resamp_europe_avrge <- projectRaster(from = qgis_resamp_europe_avrge,
res = (1/112),
crs = CRS('+init=EPSG:4326'),
method="bilinear",
alignOnly=FALSE, over=FALSE,
filename="")
qgis_resamp_europe_avrge
qgis_resamp_europe_avrge <- paste0(path2data, "/europa1000_aver.tif")
qgis_resamp_europe_avrge <- raster(qgis_resamp_europe_avrge)
qgis_resamp_europe_avrge <- projectRaster(from = qgis_resamp_europe_avrge,
res = (1/112),
crs = CRS('+init=EPSG:4326'),
method="bilinear",
alignOnly=FALSE, over=FALSE,
filename="")
qgis_resamp_europe_avrge
my_extent <- extent(qgis_resamp_europe_avrge)
# Checking correspondence with 1km PROBA-V products
# The following vectors contain Long and Lat coordinates, respectively, of the 1km grid (cell boundaries):
x_ext <- seq((-180 - ((1 / 112) / 2)), 180, (1/112))
y_ext <- seq((80 + ((1 / 112) / 2)), - 60, - (1/112))
if(!all(round(my_extent[1], 7) %in% round(x_ext, 7) &
round(my_extent[2], 7) %in% round(x_ext, 7) &
round(my_extent[3], 7) %in% round(y_ext, 7) &
round(my_extent[4], 7) %in% round(y_ext, 7))){
# The given extent from raster or coordinate vector does not fit into the 1km PROBA-V grid, so we are going to adjust it
for(crd in 1:length(as.vector(my_extent))){
if(crd <= 2){
my_extent[crd] <- x_ext[order(abs(x_ext - my_extent[crd]))][1]
}else{
my_extent[crd] <- y_ext[order(abs(y_ext - my_extent[crd]))][1]
}
}
}
as.vector(my_extent)
## Reading in data 1km global ####
ndvi_1km_orig <- raster(ndvi_1km_orig)
#cropping to Europe
ndvi_1km_orig_Eur <- crop(ndvi_1km_orig, my_extent)
summary(as.data.frame(ndvi_1km_orig_Eur))
nc <- nc_open(ndvi_1km_orig)
ndvi_1km_orig
nc <- nc_open(paste0(path2data, "/ndvi_v2_1km_c_gls_NDVI_202005010000_GLOBE_PROBAV_V2.2.1.nc"))
lon <- ncvar_get(nc, "lon")
lat <- ncvar_get(nc, "lat")
# if you have time series (I guess this is the case for Copernicus data)
time <- ncvar_get(nc, "time") # need to find the right name in 'nc'
# variable 1
ndvi1km <- ncvar_get(nc, "NDVI")
lon[1]
as.vector(summary(as.data.frame(ndvi_1km_orig_Eur)))
sum(is.na(as.data.frame(ndvi_1km_orig_Eur)))
ncatt_get(nc)
ncatt_get(nc, "valid_range")
nc
ncatt_get(nc, "Normalized Difference Vegetation Index 1KM")
ncatt_get(nc, "NDVI")
head(ndvi1km)
dim(ndvi1km)
head(ndvi1km[1,1])
head(ndvi1km[1000,1000])
head(ndvi1km[1000:5000, 1000:5000])
summary(ndvi1km[1000:5000, 1000:5000])
max(ndvi1km[1000:5000, 1000:5000])
max(ndvi1km[1000:5000, 1000:5000], na.rm = T)
ncatt_get(nc, "NDVI")
max(ndvi1km[1000:5000, 1000:5000], na.rm = T)
max(ndvi_1km_orig)
maxValue(ndvi_1km_orig)
max(as.data.frame(ndvi_1km_orig))
max(as.data.frame(ndvi_1km_orig_Eur))
nc_file300m <- paste0(path2data, "c_gls_NDVI300_PROD-DESC_202005010000_GLOBE_PROBAV_V1.0.1.nc")
## Reading in data 300m ####
ndvi_300m_orig <- raster(nc_file300m)
nc_file300m <- paste0(path2data, "/c_gls_NDVI300_PROD-DESC_202005010000_GLOBE_PROBAV_V1.0.1.nc")
## Reading in data 300m ####
ndvi_300m_orig <- raster(nc_file300m)
kk <- c(1,2,3,4,5,6,NA,NA,NA)
x <- c(1,2,3,4,5,6,NA,NA,NA)
n_valid <- sum(!is.na(x))
n_valid
n_valid > 4
dts <- list()
if(is.null(dts$na_rm)) dts$na_rm <- TRUE
dts$na_rm
x^2
sum(x^2, na.rm = dts$na_rm)
sqrt(sum(x^2, na.rm = dts$na_rm))
sqrt(sum(x^2, na.rm = dts$na_rm)) / n_valid
sqrt(sum(x^2, na.rm = dts$na_rm)) / 9
library(raster)
if(require(knitr) == FALSE){install.packages("knitr", repos = "https://cloud.r-project.org"); library(knitr)} else {library(knitr)}
# ndvi_files is a list of the available files (netCFD or Raster* objects)
ndvi_files <- list(paste0(getwd(), "/ndvi300m_Cat_kk.tif"))
r <- raster(ndvi_files[[1]])
cutoff_method_df <- read.csv(paste0(getwd(), "/Table_cutoff_and_resampleMethod.csv"),
stringsAsFactors = FALSE,
header = TRUE)
kable(cutoff_method_df[, 1:7], caption = "")
cutoff_flag <- 0.92
r[r > cutoff_flag] <- NA
if(extent(r)[1] < -180 & extent(r)[2] > 179.997 &
extent(r)[3] < -59.99554 & extent(r)[4] > 80){  # checking for full product (image)
extnt_r <- extent(r)
extnt_r[1] <- extent(r)[1] + (2 * (1 / 336)) # x-min
extnt_r[2] <- extent(r)[2] - (1 * (1 / 336)) # x-max
extnt_r[3] <- extent(r)[3] + (1 * (1 / 336))  # y-min
extnt_r[4] <- extent(r)[4] - (2 * (1 / 336))  # y-max
r <- crop(r, extnt_r)
}else{
print("The image is not the full product; therefore, extent needs to be checked")
}
ndvi_files_1km <- list(paste0(getwd(), "/ndvi1km_Cat.tif"))
r_1km <- raster(ndvi_files_1km[[1]])
if(exists("r_1km") & all(round(res(r_1km), 10) == round(0.0089285714, 10))){
my_extent <- extent(r_1km)
}else{
stop("The given raster file does not exist or does not have the 1km resolution.")
}
coords4subset <- c(0, 4, 40, 43)
my_extent <- extent(coords4subset)
# The following vectors contain Long and Lat coordinates, respectively, of the 1km grid (cell boundaries):
x_ext <- seq((-180 - ((1 / 112) / 2)), 180, (1/112))
y_ext <- seq((80 + ((1 / 112) / 2)), - 60, - (1/112))
if(!all(round(my_extent[1], 7) %in% round(x_ext, 7) &
round(my_extent[2], 7) %in% round(x_ext, 7) &
round(my_extent[3], 7) %in% round(y_ext, 7) &
round(my_extent[4], 7) %in% round(y_ext, 7))){
# The given extent from raster or coordinate vector does not fit into the 1km PROBA-V grid, so we are going to adjust it
for(crd in 1:length(as.vector(my_extent))){
if(crd <= 2){
my_extent[crd] <- x_ext[order(abs(x_ext - my_extent[crd]))][1]
}else{
my_extent[crd] <- y_ext[order(abs(y_ext - my_extent[crd]))][1]
}
}
# Now we can crop the 300m raster
r <- crop(r, my_extent)
}
kable(cutoff_method_df[, c(1:2, 8)], caption = "")
#aggr_method <- "mean_w.cond"
#aggr_method <- "closest_to_mean"
#aggr_method <- "uncert_propag"
mean_w.cond <- function(x, ...){ # mean including condition 'minimum 5 valid pixels'
n_valid <- sum(!is.na(x)) # number of cells with valid value
if(n_valid > 4){
dts <- list(...)
if(is.null(dts$na_rm)) dts$na_rm <- TRUE
x_mean <- mean(x, na.rm = dts$na_rm)
return(x_mean)
}else{
x_mean <- NA
return(x_mean)
}
}
closest_to_mean <- function(x, ...){
n_valid <- sum(!is.na(x)) # number of cells with valid value
if(n_valid > 4){  # minimum 5 valid pixels
dts <- list(...)
if(is.null(dts$na_rm)) dts$na_rm <- TRUE
x_mean <- mean(x, na.rm = dts$na_rm)
closest2avrge <- x[order(abs(x - x_mean))][1]
return(closest2avrge)
}else{
closest2avrge <- NA
return(closest2avrge)
}
}
uncert_propag <- function(x, ...){ # uncertainty_propagation (including condition 'minimum 5 valid pixels')
n_valid <- sum(!is.na(x)) # number of cells with valid value
if(n_valid > 4){
dts <- list(...)
if(is.null(dts$na_rm)) dts$na_rm <- TRUE
unc_prp <- sqrt(sum(x^2, na.rm = dts$na_rm)) / n_valid
return(unc_prp)
}else{
unc_prp <- NA
return(unc_prp)
}
}
aggr_method <- "mean_w.cond"
r300m_resampled1km_Aggr <- aggregate(r,
fact = 3, # from 333m to 1km
fun = aggr_method,
na.rm = TRUE,
filename = '')
plot(r, main = 'Original map at 300m')
plot(r300m_resampled1km_Aggr, main = 'Resampled map to 1km')
